# An√°lise de Capacidade do Sistema - MonPEC Gest√£o Rural

## üìä Cen√°rio de Carga Esperado
- **10.000 clientes** (produtores rurais)
- **40.000 propriedades**
- **200+ milh√µes de registros** (animais, pesagens, movimenta√ß√µes, etc.)

## ‚ö†Ô∏è PROBLEMAS CR√çTICOS IDENTIFICADOS

### 1. **BANCO DE DADOS INADEQUADO - CR√çTICO** üî¥

**Situa√ß√£o Atual:**
```python
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': BASE_DIR / 'db.sqlite3',
    }
}
```

**Problemas:**
- SQLite **N√ÉO suporta** 200 milh√µes de registros de forma eficiente
- Limita√ß√µes de concorr√™ncia (apenas 1 escrita por vez)
- Tamanho m√°ximo de arquivo: ~140 TB (te√≥rico), mas performance degrada muito antes
- Sem suporte adequado para m√∫ltiplos usu√°rios simult√¢neos
- Lock de escrita bloqueia todas as opera√ß√µes

**Impacto:** Sistema **VAI TRAVAR** com essa carga.

**Solu√ß√£o Obrigat√≥ria:**
- Migrar para **PostgreSQL** ou **MySQL/MariaDB**
- PostgreSQL √© recomendado para grandes volumes de dados

---

### 2. **QUERIES SEM PAGINA√á√ÉO - CR√çTICO** üî¥

**Problema Identificado em `views_pesagem.py` (linha 89):**
```python
for pesagem in pesagens_qs:  # Carrega TODAS as pesagens na mem√≥ria!
    # Processamento...
```

**Impacto:**
- Com milh√µes de pesagens, isso vai:
  - Esgotar mem√≥ria RAM do servidor
  - Travar o servidor
  - Causar timeout nas requisi√ß√µes

**Outros locais problem√°ticos:**
- `views_pecuaria_completa.py`: Carrega m√∫ltiplas queries sem limites
- `views_financeiro.py`: Agrega√ß√µes sem otimiza√ß√£o
- V√°rias views fazem `.count()` e `.aggregate()` sem cache

---

### 3. **FALTA DE CACHE - ALTO** üü°

**Situa√ß√£o:**
- Nenhuma configura√ß√£o de cache no `settings.py`
- Queries repetitivas s√£o executadas toda vez
- Dashboards recalculam tudo a cada acesso

**Impacto:**
- Performance degradada
- Sobrecarga desnecess√°ria no banco
- Experi√™ncia do usu√°rio ruim

---

### 4. **√çNDICES INSUFICIENTES - M√âDIO** üü°

**Situa√ß√£o:**
- Alguns √≠ndices existem (vistos em migrations)
- Mas n√£o cobrem todas as queries cr√≠ticas
- Foreign keys sem √≠ndices em alguns casos

**Impacto:**
- Queries lentas mesmo com poucos dados
- Com milh√µes de registros, ser√° insuport√°vel

---

### 5. **FALTA DE OTIMIZA√á√ïES DE QUERY - M√âDIO** üü°

**Problemas:**
- Uso de `select_related()` e `prefetch_related()` inconsistente
- N+1 queries em v√°rios lugares
- Agrega√ß√µes sem otimiza√ß√£o

---

## ‚úÖ RECOMENDA√á√ïES PRIORIT√ÅRIAS

### PRIORIDADE 1 - URGENTE (Fazer ANTES de escalar)

#### 1.1 Migrar para PostgreSQL
```python
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME'),
        'USER': config('DB_USER'),
        'PASSWORD': config('DB_PASSWORD'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
        'OPTIONS': {
            'connect_timeout': 10,
        },
        'CONN_MAX_AGE': 600,  # Connection pooling
    }
}
```

**Benef√≠cios:**
- Suporta bilh√µes de registros
- Concorr√™ncia real (m√∫ltiplas escritas simult√¢neas)
- Performance superior
- Ferramentas de otimiza√ß√£o avan√ßadas

#### 1.2 Implementar Pagina√ß√£o em TODAS as Listagens
```python
# Exemplo correto:
from django.core.paginator import Paginator

def minha_view(request):
    queryset = Modelo.objects.filter(...)
    paginator = Paginator(queryset, 50)  # 50 por p√°gina
    page = request.GET.get('page', 1)
    page_obj = paginator.get_page(page)
    return render(request, 'template.html', {'page_obj': page_obj})
```

**Arquivos a corrigir:**
- `gestao_rural/views_pesagem.py` (linha 89)
- `gestao_rural/views_pecuaria_completa.py`
- `gestao_rural/views_financeiro.py`
- Todas as views que listam dados

#### 1.3 Implementar Cache
```python
# settings.py
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.redis.RedisCache',
        'LOCATION': config('REDIS_URL', default='redis://127.0.0.1:6379/1'),
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        },
        'KEY_PREFIX': 'monpec',
        'TIMEOUT': 300,  # 5 minutos padr√£o
    }
}

# Usar em views:
from django.views.decorators.cache import cache_page

@cache_page(60 * 5)  # Cache por 5 minutos
def dashboard(request):
    # ...
```

---

### PRIORIDADE 2 - IMPORTANTE (Fazer em seguida)

#### 2.1 Adicionar √çndices Estrat√©gicos
```python
# models.py
class AnimalPesagem(models.Model):
    # ...
    class Meta:
        indexes = [
            models.Index(fields=['animal', '-data_pesagem']),
            models.Index(fields=['animal', 'data_pesagem']),
            models.Index(fields=['data_pesagem']),
        ]
```

**√çndices cr√≠ticos necess√°rios:**
- `animal_id + data_pesagem` (para queries de hist√≥rico)
- `propriedade_id + data` (para filtros por propriedade e per√≠odo)
- `status + data` (para dashboards)
- Todos os Foreign Keys

#### 2.2 Otimizar Queries com select_related/prefetch_related
```python
# Antes (N+1 queries):
pesagens = AnimalPesagem.objects.filter(...)
for p in pesagens:
    print(p.animal.nome)  # Query adicional para cada animal!

# Depois (1 query):
pesagens = AnimalPesagem.objects.filter(...).select_related('animal')
for p in pesagens:
    print(p.animal.nome)  # Sem queries adicionais!
```

#### 2.3 Implementar Lazy Loading e Streaming
Para relat√≥rios grandes, usar streaming:
```python
from django.http import StreamingHttpResponse

def exportar_grande(request):
    def gerar_dados():
        queryset = Modelo.objects.filter(...).iterator(chunk_size=1000)
        for item in queryset:
            yield processar_item(item)
    
    return StreamingHttpResponse(gerar_dados())
```

---

### PRIORIDADE 3 - MELHORIAS (Fazer gradualmente)

#### 3.1 Implementar Database Sharding/Partitioning
Para 200M+ registros, considerar:
- Particionamento por ano/m√™s em tabelas grandes
- Sharding por propriedade ou regi√£o

#### 3.2 Implementar Read Replicas
- Um servidor para escritas
- M√∫ltiplos servidores para leituras (dashboards, relat√≥rios)

#### 3.3 Implementar Background Tasks
- Processar relat√≥rios pesados em background (Celery)
- Cache de c√°lculos complexos

#### 3.4 Monitoramento e Alertas
- Implementar logging de queries lentas
- Alertas quando queries excederem threshold
- Dashboard de performance

---

## üìà CAPACIDADE ESTIMADA AP√ìS CORRE√á√ïES

### Com PostgreSQL + Otimiza√ß√µes B√°sicas:
- ‚úÖ **10.000 clientes**: Suportado
- ‚úÖ **40.000 propriedades**: Suportado
- ‚ö†Ô∏è **200M registros**: Suportado, mas requer:
  - Particionamento de tabelas grandes
  - √çndices adequados
  - Cache agressivo
  - Read replicas para dashboards

### Com Todas as Otimiza√ß√µes:
- ‚úÖ **10.000 clientes**: Suportado facilmente
- ‚úÖ **40.000 propriedades**: Suportado facilmente
- ‚úÖ **200M+ registros**: Suportado com:
  - Particionamento
  - Read replicas
  - Cache Redis
  - Background processing

---

## üö® CONCLUS√ÉO

**RESPOSTA DIRETA:** 

**N√ÉO, o sistema atual N√ÉO √© capaz de suportar essa carga sem travar.**

**Principais bloqueadores:**
1. SQLite n√£o suporta essa escala
2. Queries sem pagina√ß√£o v√£o esgotar mem√≥ria
3. Falta de cache sobrecarrega o banco

**A√ß√µes obrigat√≥rias antes de escalar:**
1. ‚úÖ Migrar para PostgreSQL
2. ‚úÖ Implementar pagina√ß√£o em todas as listagens
3. ‚úÖ Adicionar cache (Redis)
4. ‚úÖ Otimizar queries cr√≠ticas
5. ‚úÖ Adicionar √≠ndices estrat√©gicos

**Tempo estimado para implementa√ß√£o:** 2-4 semanas

**Ap√≥s implementa√ß√£o:** Sistema ser√° capaz de suportar a carga esperada.

---

## üìù CHECKLIST DE MIGRA√á√ÉO

- [ ] 1. Configurar PostgreSQL em ambiente de desenvolvimento
- [ ] 2. Criar script de migra√ß√£o de dados do SQLite para PostgreSQL
- [ ] 3. Testar migra√ß√£o com dados de teste
- [ ] 4. Implementar pagina√ß√£o em todas as views de listagem
- [ ] 5. Adicionar cache Redis
- [ ] 6. Adicionar √≠ndices cr√≠ticos
- [ ] 7. Otimizar queries com select_related/prefetch_related
- [ ] 8. Testes de carga (simular 10k clientes, 40k propriedades)
- [ ] 9. Monitoramento e alertas
- [ ] 10. Deploy gradual (staging ‚Üí produ√ß√£o)

---

## üîß SCRIPTS √öTEIS

### Verificar queries lentas:
```python
# settings.py
LOGGING = {
    'version': 1,
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
        },
    },
    'loggers': {
        'django.db.backends': {
            'level': 'DEBUG',
            'handlers': ['console'],
        },
    },
}
```

### Verificar uso de mem√≥ria:
```python
import psutil
import os

process = psutil.Process(os.getpid())
print(f"Mem√≥ria usada: {process.memory_info().rss / 1024 / 1024:.2f} MB")
```

---

**√öltima atualiza√ß√£o:** 2024
**Respons√°vel pela an√°lise:** Sistema de An√°lise Autom√°tica






